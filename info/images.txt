$>docker pull container_name
$>docker image ls

(if there is no bash inside container)

Image is:
Simply - It's an app binaries and dependencies for your App, and metadata about image and how to run it.
Official - ordered collection of root filesystem changes and the corresponding execution parameters for 
  use within a container runtime.

So there is no real OS inside images. There no kernel, kernel modules (e.g. drivers) Because kernel is 
  provided by docker itself (it's always a tiny Linux, remember?). So there is no booting a real virtual 
  machine. There only binaries of applications that you need. Of course there are big images of ubuntu
  distribution, with their own package manager and all stuff. But still it's not a separate OS.

Docker HUB
Its like npm for docker images.

Only official images has name without "/" in it. If we create image -> it will be
  organization_name(user_name)/image_name.
Versions - in description there are a few one:
  mainline - latest version
  stable - respectively (соответственно)
  If we look closer to description of nginx image on docker hub
  1.17.0, mainline, 1, 1.17, latest (mainline/stretch/Dockerfile)
  1.16.0, stable, 1.16 (stable/stretch/Dockerfile)
If image is not official - we can rely on stars and pulls. Same with github.

  All these things is tags. And to pull latest/mainline version of image - we can use them. So one image
  can have multiple tags.
  $>docker pull nginx:1.17 | nginx:mainline | nginx:latest | nginx:1 -> will download only one image but in list
  of your images will be several rows under different tags.

  $>docker image ls
  REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE 
  nginx               1                   62c261073ecf        41 hours ago        109MB
  nginx               1.17                62c261073ecf        2 days ago          109MB
  nginx               latest              53f3fd8007f7        4 weeks ago         109MB
  bondrukoleh/nginx   latest              53f3fd8007f7        4 weeks ago         109MB
  mysql               latest              990386cbd5c0        3 weeks ago         443MB
  bretfisher/node-docker   latest         214806ce25ce        2 weeks ago         928MB

  You can see TAG column. That was "docker pull nginx:1 nginx:1.17", it's the same latest container but under
  different tag.
  If we don't specify tag -> we will download latest one.

  mainline-alpine - is the small Linux distribution, and nginx default docker is from jessie, Debian 
  distribution which is larger. 

TAGS
Images doesn't technically have name. As you can see they have REPOSITORY and TAG columns.
Repository - it's either username or the organization_name/repository. Official repository has only name.
As we can see, users have something like bretfisher/node-docker, organization like mysql/mysql-server.
Tag - it's a pointer for some specific image commit, it's a part from github tags, and a part from name,
and a part from labels.

To add a new tag to existing image:
$>docker image tag source_image:tag_name target_image:tag_name
$>docker image tag nginx bondarukoleh/nginx -> if we don't specify tag - "latest" is default one.

Before push - we should create a repository with name of docker. For example
we create repository named node10_with_ubuntu.
That we build image with this name 
$>docker build -t bondarukoleh/node10_with_ubuntu:basic .
and then we can push
$>docker push bondarukoleh/node10_with_ubuntu:latest

We can push container to our docker hub.
$>docker image push bondarukoleh/nginx -> username/ should be the same with yours.

You should do login before push. We can specify url you want to login to.
$>docker login

Pay attention that if you've logged in via docker cli, in ~/.docker/config.json
there are "auth" info with your key. So it's better to logout after you finish your deals with docker, especial
when you worked on shared servers and machines.

So we pushed an image to docker hub. If we add another tag to it, and have "different" image tagged locally and
try to push it to docker hub -> we'll see that such layer already exists message. So it works the same way, if
something already exist - we don't store it twice.

We also have ability to create private repositories in docker hub.

IMAGE LAYERS
  So image - it's not a big blob of data. Images is designed to use UNION file system concept of making layers about
  the changes. 

  If we will look at the history of image, nginx for example:
  $>docker image history nginx:latest
  IMAGE               CREATED             CREATED BY                                      SIZE                COMMENT
53f3fd8007f7        4 weeks ago         /bin/sh -c #(nop)  CMD ["nginx" "-g" "daemon…   0B
*<missing>          4 weeks ago         /bin/sh -c #(nop)  STOPSIGNAL SIGTERM           0B
<missing>           4 weeks ago         /bin/sh -c #(nop)  EXPOSE 80                    0B
<missing>           4 weeks ago         /bin/sh -c ln -sf /dev/stdout /var/log/nginx…   22B
<missing>           4 weeks ago         /bin/sh -c set -x  && apt-get update  && apt…   54.1MB
<missing>           4 weeks ago         /bin/sh -c #(nop)  CMD ["bash"]                 0B
<missing>           4 weeks ago         /bin/sh -c #(nop) ADD file:fcb9328ea4c115670…   55.3MB

*<missing> - means that this is layer inside the top one, it's just how docker shows it, it has SHA, but docker
guys for some reason decided not to show it here.

We'll see what was happening in image. It's a history of image layers. Some changes were costed new space for them, 
some were just a metadata changes.

When we creating a new image - we starting with first (scratch) layer. Each layer has his uniq SHA (hash) that helps 
system to understand is there was changed something, that also helps to understand is layer we want to create is
already exist.

Creating Image:

This is container with node app.                                                  This is container with Java app.
 || |--------------------------------|        We expose 3000 port - docker doesn't create         ||
 || | 5th layer. Expose 3000 port    |        another layer for this, it understand that          ||
 || |--------------------------------|        hash is the same so it uses already created one     ||
 || |--------------------------------|        |--------------------------------|                  ||
 || | 4th layer. Install Node app    |        | 4th layer. Install Java app    |                  ||
 || |--------------------------------|        |--------------------------------|                  ||
 || |--------------------------------|        |--------------------------------|                  ||
 || | 3nd layer. Added some ENV vars |        | 3nd layer. Added some ENV vars |                  ||
 || |--------------------------------|        |--------------------------------|                  ||
 || |-----------------------------------|                                                         ||
 || | 2nd. Curl installed via apt-get   |  We want to install curl, but we don't do               ||
 || |-----------------------------------|   it twice, we use  already created layer               ||
 || |--------------------------------------|  We want another image with Ubuntu - docker will     ||
 || |      1st layer. Ubuntu Image Created |  use already created layer for different image       ||
 \/ |--------------------------------------|  since it is the same data we need.                  \/

As you can see we have two different images, but they are using three same layers of data.
So locally we keep all this information, in cache, and when we try to download new images - docker compares
local hash with hash from docker hub, and understands are we have something already here. locally.
Main idea - is that we never have two copies of same layer. It stored only once.

RUNNING CONTAINERS
We start container from our image of Node app. That means that docker started a new Read/Write layer on top 
of the Node app image. So the container -> is a new stack of layers that keeps differencing between the image
which is READ-ONLY (sic!) and the new changes made in container. If in the container some physical file was
changed from the image, docker creates a copy of this file, and store changed file in container layer.
This is Copy-On-Write strategy, COW. But be aware, since new copy of modified file is in container level, as 
all changes - is in container level, when container is deleted - changes are also deleted, if you haven't
setup some mount folder os something.

docker inspect - shows the metadata. As it was said - image it's a binaries that will run and metadata how it
preferred to be run.
$>docker inspect mysql
...
 "Config": {
            "Hostname": "8cd6617b3cb3",
            "Domainname": "",
            "User": "",
            "AttachStdin": false,
            "AttachStdout": false,
            "AttachStderr": false,
            "ExposedPorts": {
                "3306/tcp": {}, -> telling us that if you want to use it - you'll need to expose 3306 port.
                "33060/tcp": {}
            },
             "Env": [ -> ENV variables that will be set in container 
                "MYSQL_RANDOM_ROOT_PASSWORD=yes",
                "PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
                "GOSU_VERSION=1.7",
                "MYSQL_MAJOR=8.0",
                "MYSQL_VERSION=8.0.16-2debian9"
            ],
            "Cmd": [ -> commands that will be run is we start container by default.
                "mysqld"
            ],
...            
As you know a lot of these stuff can be changed when we create a container, but it shows us the default config.
